{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pymcdm\n",
    "import plotly\n",
    "\n",
    "\n",
    "use_mcdm = True\n",
    "metric = \"overall_acc\"\n",
    "# metric = \"matthews_corrcoef\"\n",
    "train_metric = f\"train_{metric}\"\n",
    "validation_metric = f\"validation_{metric}\"\n",
    "holdout_metric = f\"holdout_{metric}\"\n",
    "test_metric = f\"test_{metric}\"\n",
    "# folder that contains the nosbss.csv\n",
    "folder = Path(\"experiments/exp0090/\")\n",
    "policies_folder = folder / f\"{metric}/policies\"\n",
    "folder.absolute()\n",
    "df_path = folder / \"politica_1_oracle_1m1l_and_nosbss.csv\"\n",
    "df_parquet_path = folder / \"politica_1_oracle_1m1l_and_nosbss.parquet\"\n",
    "datasets = [\n",
    "    \"ionosphere\",\n",
    "    \"diabetes\",\n",
    "    \"Australian\",\n",
    "    \"car(3)\",\n",
    "    \"credit-g\",\n",
    "    \"climate-model-simulation-crashes(4)\",\n",
    "    \"ilpd\",\n",
    "    \"balance-scale\",\n",
    "    \"libras_move\",\n",
    "    # \"hill-valley\",\n",
    "    \"blood-transfusion-service-center\",\n",
    "    \"lsvt\",\n",
    "    \"wdbc\",\n",
    "    \"satimage\",\n",
    "    \"vowel(2)\",\n",
    "    # \"musk\",\n",
    "]\n",
    "experiments = [\n",
    "    \"exp0090_politica_1_oracle_1m1l\",\n",
    "    # \"exp0090_politica_1_oracle_1m1l_nosbss\",\n",
    "]\n",
    "\n",
    "policies = [\n",
    "    \"oracle\",\n",
    "    \"holdout\",\n",
    "    \"pareto_second_best_holdout_num_neurons\",\n",
    "    \"validation\",\n",
    "    \"0.01_smallest_mean_dist_holdout\",\n",
    "    \"smallest_euclidian_holdout_test_utopic\",\n",
    "    \"best_holdout_in_best_architecture_10fold\",\n",
    "]\n",
    "\n",
    "if use_mcdm:\n",
    "    policies += [\n",
    "        \"topsis_pareto_oracle\",\n",
    "        \"topsis_pareto_holdout\",\n",
    "        \"topsis_pareto_holdout_no_epochs\",\n",
    "        \"topsis_pareto_holdout_no_num_neurons\",\n",
    "        \"topsis_pareto_holdout_weighted_neu-p3_epc-p1_hold-p6\",\n",
    "        \"topsis_pareto_holdout_weighted_neu-p1_epc-p1_hold-p8\",\n",
    "        \"topsis_pareto_holdout_mean_diffs\",\n",
    "        \"all_except_test\",\n",
    "        \"topsis_all_overall_acc_except_test\",\n",
    "        \"topsis_train_validation_holdout_no_num_neurons_no_epochs\",\n",
    "        \"topsis_pareto_train_validation_holdout\",\n",
    "        \"topsis_pareto_train_validation_holdout_no_epochs\",\n",
    "        \"topsis_best_rank_architecture_pareto_train_validation_holdout_no_epochs\",\n",
    "        \"topsis_pareto_oracle_holdout_no_epochs_no_num_neurons\",\n",
    "        \"topsis_pareto_oracle_holdout_train\",\n",
    "        \"topsis_pareto_oracle_holdout_train_noepochs_nonum_neurons\",\n",
    "        \"topsis_pareto_oracle_holdout_validation_train\",\n",
    "        \"topsis_pareto_oracle_holdout_validation_train_noepochs_nonum_neurons\",\n",
    "        \"topsis_holdout_in_best_median_architecture_10fold_nopareto\",\n",
    "        \"mairca_pareto_holdout\",\n",
    "        \"mairca_pareto_holdout_reverse\",\n",
    "        \"moora_pareto_holdout\",\n",
    "        \"moora_pareto_holdout_inverse\",\n",
    "    ]\n",
    "    analysis_folder = folder / f\"{metric}/plots\"\n",
    "else:\n",
    "    analysis_folder = folder / f\"{metric}/plots_no_topsis\"\n",
    "\n",
    "analysis_folder.mkdir(parents=True, exist_ok=True)\n",
    "policies_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'Unnamed: 0', 'model_id', 'selected', 'fold', 'repetition',\n",
      "       'num_neurons', 'weight_regularization', 'monitored_metric', 'loss',\n",
      "       'epoch', 'activation_name', 'architecture_id', 'train_overall_acc',\n",
      "       'train_matthews_corrcoef', 'validation_overall_acc',\n",
      "       'validation_matthews_corrcoef', 'holdout_overall_acc',\n",
      "       'holdout_matthews_corrcoef', 'test_overall_acc',\n",
      "       'test_matthews_corrcoef', 'dominant_solution', 'mean_diffs', 'dataset',\n",
      "       'run', 'experiment', 'validation_loss', 'holdout_loss'],\n",
      "      dtype='object')\n",
      "df.shape: (1411200, 28)\n",
      "datase: ['ionosphere' 'diabetes' 'Australian' 'car(3)' 'credit-g'\n",
      " 'climate-model-simulation-crashes(4)' 'ilpd' 'balance-scale'\n",
      " 'libras_move' 'blood-transfusion-service-center' 'lsvt' 'wdbc' 'satimage'\n",
      " 'vowel(2)']\n",
      "df_policies.shape: (6048, 32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def csv_to_parquet():\n",
    "    df = pd.read_csv(df_path)\n",
    "    df.to_parquet(df_parquet_path)\n",
    "\n",
    "\n",
    "def load_df():\n",
    "    df = pd.read_parquet(df_parquet_path)\n",
    "    # Removing repeated experiments\n",
    "    non_duplicated_index = (\n",
    "        df[[\"experiment\", \"dataset\", \"run\", \"model_id\"]].drop_duplicates()\n",
    "    ).index\n",
    "    df = df.loc[non_duplicated_index].reset_index()\n",
    "    df[\"mean_diffs\"] = (\n",
    "        abs(df[holdout_metric] - df[train_metric])\n",
    "        + abs(df[holdout_metric] - df[validation_metric])\n",
    "        + abs(df[train_metric] - df[validation_metric])\n",
    "    ) / 3\n",
    "    print(df.keys())\n",
    "    df = df[(df[\"experiment\"].isin(experiments)) & (df[\"dataset\"].isin(datasets))]\n",
    "    print(f\"df.shape: {df.shape}\")\n",
    "    print(f\"datase: {df['dataset'].unique()}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_df_policies():\n",
    "    policies_files = policies_folder.glob(\"**/*.csv\")\n",
    "    df_policies = pd.concat(\n",
    "        [\n",
    "            pd.read_csv(policy_file_path)\n",
    "            for policy_file_path in policies_files\n",
    "            if policy_file_path.name.replace(\".csv\", \"\") in policies\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    df_policies = df_policies[\n",
    "        (df_policies[\"experiment\"].isin(experiments))\n",
    "        & (df_policies[\"dataset\"].isin(datasets))\n",
    "    ]\n",
    "\n",
    "    print(f\"df_policies.shape: {df_policies.shape}\")\n",
    "    return df_policies\n",
    "\n",
    "\n",
    "def load_df_times():\n",
    "    df_times_cuda = pd.read_csv(Path(\"experiments/times_cuda/times_cuda.csv\"))\n",
    "    df_times_cpu = pd.read_csv(Path(\"experiments/times_cpu/times_cpu.csv\"))\n",
    "    # for df_device_key, df in dfs.items():\n",
    "    # #,num_samples,num_features,min_neurons,max_neurons,epochs,num_models,activation_functions,repetitions,sequential,parallel,device,parallel/sequential\n",
    "    #     df = df.drop(columns=[\"min_neurons\", \"max_neurons\", \"epochs\", \"repetitions\", \"activation_functions\", \"repetitions\"])\n",
    "    #     df = df.melt(id_vars=[\"num_samples\", \"num_features\", \"num_models\", \"device\"])\n",
    "    # df_times_cpu = pd.read_csv(Path(\"experiments/times_cuda/times_cpu.csv\"))\n",
    "    df = pd.concat((df_times_cuda, df_times_cpu))\n",
    "\n",
    "    df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "# df_times = load_df_times()\n",
    "# plot_times(df_times)\n",
    "\n",
    "# csv_to_parquet()\n",
    "\n",
    "df = load_df()\n",
    "# apply_policies(df)\n",
    "df_policies = load_df_policies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_holdout_test(df):\n",
    "    fig = px.scatter(\n",
    "        df.sort_values(by=[test_metric, holdout_metric]),\n",
    "        x=holdout_metric,\n",
    "        y=test_metric,\n",
    "        color=\"dataset\",\n",
    "        symbol=\"experiment\",\n",
    "    )\n",
    "\n",
    "    fig.write_html(analysis_folder / \"holdout__test.html\")\n",
    "\n",
    "\n",
    "def debug_ilpd(df):\n",
    "    df = df.copy()\n",
    "    df[df[\"dataset\"] == \"ilpd\"].to_csv(analysis_folder / \"debug_ilpd.csv\")\n",
    "\n",
    "\n",
    "def num_models(df):\n",
    "    # should be \t1,612,800\n",
    "    df.groupby([\"experiment\", \"dataset\", \"run\"]).size().to_csv(\n",
    "        analysis_folder / \"num_models.csv\"\n",
    "    )\n",
    "\n",
    "\n",
    "def is_pareto_efficient(costs, return_mask=True):\n",
    "    \"\"\"\n",
    "    Find the pareto-efficient points\n",
    "    :param costs: An (n_points, n_costs) array of costs to be minimized\n",
    "    :param return_mask: True to return a mask\n",
    "    :return: An array of indices of pareto-efficient points.\n",
    "        If return_mask is True, this will be an (n_points, ) boolean array\n",
    "        Otherwise it will be a (n_efficient_points, ) integer array of indices.\n",
    "    \"\"\"\n",
    "    is_efficient = np.arange(costs.shape[0])\n",
    "    n_points = costs.shape[0]\n",
    "    next_point_index = 0  # Next index in the is_efficient array to search for\n",
    "    while next_point_index < len(costs):\n",
    "        nondominated_point_mask = np.any(costs < costs[next_point_index], axis=1)\n",
    "        nondominated_point_mask[next_point_index] = True\n",
    "        is_efficient = is_efficient[nondominated_point_mask]  # Remove dominated points\n",
    "        costs = costs[nondominated_point_mask]\n",
    "        next_point_index = np.sum(nondominated_point_mask[:next_point_index]) + 1\n",
    "    if return_mask:\n",
    "        is_efficient_mask = np.zeros(n_points, dtype=bool)\n",
    "        is_efficient_mask[is_efficient] = True\n",
    "        return is_efficient_mask\n",
    "    else:\n",
    "        return is_efficient\n",
    "\n",
    "\n",
    "def get_ranked_pmlps_df(\n",
    "    pmlps_df,\n",
    "    mcdm_tuples,\n",
    "    theoretical_best=None,\n",
    "    theoretical_worst=None,\n",
    "    only_pareto_solutions=True,\n",
    "    sort_by_rank=False,\n",
    "    weights=None,\n",
    "    mcdm_method_name=\"topsis\",\n",
    "):\n",
    "\n",
    "    pmlps_df = pmlps_df.copy()\n",
    "\n",
    "    mcdm_keys = [k[0] for k in mcdm_tuples]\n",
    "\n",
    "    types = np.array([k[1] for k in mcdm_tuples])\n",
    "    mcdm_method_map = {\n",
    "        \"topsis\": pymcdm.methods.TOPSIS(pymcdm.normalizations.minmax_normalization),\n",
    "        \"moora\": pymcdm.methods.MOORA(),\n",
    "        \"mairca\": pymcdm.methods.MAIRCA(),\n",
    "        None: None,\n",
    "    }\n",
    "    mcdm_method = mcdm_method_map[mcdm_method_name]\n",
    "\n",
    "    decision_matrix = pmlps_df[mcdm_keys].to_numpy()\n",
    "    pareto_matrix = decision_matrix.copy()\n",
    "\n",
    "    for c in range(pareto_matrix.shape[1]):\n",
    "        # types inform if is profit (1 - should be maximized) or cost (-1 - should be minimized)\n",
    "        # is_pareto_efficient expectes a matrix of costs to minimize\n",
    "        # that's why i am multipying by -types[c]\n",
    "        pareto_matrix[:, c] *= -types[c]\n",
    "\n",
    "    pareto_mask = is_pareto_efficient(pareto_matrix)\n",
    "    pmlps_df[\"dominant_solution\"] = pareto_mask\n",
    "\n",
    "    if theoretical_best is not None:\n",
    "        if theoretical_worst is None:\n",
    "            raise ValueError(\n",
    "                \"Both theoretical_best and theoretical_worst must be None or have values.\"\n",
    "            )\n",
    "        decision_matrix = np.vstack(\n",
    "            (decision_matrix, theoretical_best, theoretical_worst)\n",
    "        )\n",
    "\n",
    "    if weights is None:\n",
    "        weights = pymcdm.weights.equal_weights(decision_matrix)\n",
    "    # # weights = np.array([0.5, 0.4, 0.1])\n",
    "    if mcdm_method is not None:\n",
    "        ranks = mcdm_method(decision_matrix, weights, types)\n",
    "        # removing best_and_worst_theoretical_mlps\n",
    "        if theoretical_best is not None:\n",
    "            ranks = ranks[:-2]\n",
    "\n",
    "        pmlps_df[\"rank\"] = ranks\n",
    "\n",
    "    if only_pareto_solutions:\n",
    "        pmlps_df = pmlps_df.loc[pareto_mask]\n",
    "\n",
    "    if sort_by_rank and \"rank\" in pmlps_df.columns:\n",
    "        pmlps_df = pmlps_df.sort_values(by=[\"rank\"], ascending=False).reset_index()\n",
    "\n",
    "    return pmlps_df\n",
    "\n",
    "\n",
    "def apply_policies(df):\n",
    "    # datasets = df[\"dataset\"].unique()\n",
    "    # datasets = [\"diabetes\", \"credit-g\"]\n",
    "    runs = df[\"run\"].unique()\n",
    "\n",
    "    for policy in policies:\n",
    "        policy_file_path = policies_folder / f\"{policy}.csv\"\n",
    "        if policy_file_path.exists():\n",
    "            continue\n",
    "        choices = []\n",
    "        for experiment in experiments:\n",
    "            for dataset in tqdm(datasets):\n",
    "                pmlps_df_dataset = df[df[\"dataset\"] == dataset]\n",
    "                for run in runs:\n",
    "                    pmlps_df = pmlps_df_dataset[\n",
    "                        (pmlps_df_dataset[\"run\"] == run)\n",
    "                        & (pmlps_df_dataset[\"experiment\"] == experiment)\n",
    "                    ]\n",
    "                    pmlps_df = pmlps_df.sort_values(\n",
    "                        by=[\"mean_diffs\", \"num_neurons\", holdout_metric],\n",
    "                        ascending=[True, True, False],\n",
    "                    )\n",
    "                    mcdm_tuples = [\n",
    "                        (\"num_neurons\", -1),\n",
    "                        (\"epoch\", 1),\n",
    "                        (holdout_metric, 1),\n",
    "                    ]\n",
    "                    ranked_pmlps_df_original = get_ranked_pmlps_df(\n",
    "                        pmlps_df, mcdm_tuples, only_pareto_solutions=False\n",
    "                    )\n",
    "                    ranked_pmlps_df = ranked_pmlps_df_original.copy()\n",
    "\n",
    "                    if policy == \"oracle\":\n",
    "                        ranked_pmlps_df = ranked_pmlps_df.sort_values(\n",
    "                            by=[test_metric, \"num_neurons\"],\n",
    "                            ascending=[False, True],\n",
    "                        )\n",
    "                    elif policy == \"holdout\":\n",
    "                        ranked_pmlps_df = ranked_pmlps_df.sort_values(\n",
    "                            by=[holdout_metric, \"num_neurons\"],\n",
    "                            ascending=[False, True],\n",
    "                        )\n",
    "                    elif policy == \"pareto_second_best_holdout_num_neurons\":\n",
    "                        mcdm_tuples = [\n",
    "                            (\"num_neurons\", -1),\n",
    "                            (holdout_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                        )\n",
    "                        ranked_pmlps_df = ranked_pmlps_df.drop(\n",
    "                            columns=[\"level_0\"]\n",
    "                        ).sort_values(\n",
    "                            by=[holdout_metric, \"num_neurons\"],\n",
    "                            ascending=[False, True],\n",
    "                        )\n",
    "                        if ranked_pmlps_df.shape[0] > 1:\n",
    "                            ranked_pmlps_df = (\n",
    "                                ranked_pmlps_df.iloc[1:].copy().reset_index()\n",
    "                            )\n",
    "                    elif policy == \"validation\":\n",
    "                        ranked_pmlps_df = ranked_pmlps_df.sort_values(\n",
    "                            by=[validation_metric, \"num_neurons\"],\n",
    "                            ascending=[False, True],\n",
    "                        )\n",
    "                    elif policy == \"best_holdout_in_best_architecture_10fold\":\n",
    "                        best_architecture = (\n",
    "                            ranked_pmlps_df.groupby([\"architecture_id\"])\n",
    "                            .mean()\n",
    "                            .sort_values(by=[holdout_metric], ascending=[False])\n",
    "                            .reset_index()\n",
    "                            .iloc[0][\"architecture_id\"]\n",
    "                        )\n",
    "                        ranked_pmlps_df = ranked_pmlps_df[\n",
    "                            ranked_pmlps_df[\"architecture_id\"] == best_architecture\n",
    "                        ]\n",
    "                        ranked_pmlps_df = ranked_pmlps_df.sort_values(\n",
    "                            by=[holdout_metric, \"num_neurons\"],\n",
    "                            ascending=[False, True],\n",
    "                        )\n",
    "                    elif (\n",
    "                        policy\n",
    "                        == \"topsis_holdout_in_best_median_architecture_10fold_nopareto\"\n",
    "                    ):\n",
    "                        mcdm_tuples = [\n",
    "                            (\"num_neurons\", -1),\n",
    "                            (\"epoch\", 1),\n",
    "                            (holdout_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            # only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                        )\n",
    "                        best_architecture = (\n",
    "                            ranked_pmlps_df.groupby([\"architecture_id\"])\n",
    "                            .median()\n",
    "                            .sort_values(by=[\"rank\"], ascending=[False])\n",
    "                            .reset_index()\n",
    "                            .iloc[0][\"architecture_id\"]\n",
    "                        )\n",
    "                        ranked_pmlps_df = ranked_pmlps_df[\n",
    "                            ranked_pmlps_df[\"architecture_id\"] == best_architecture\n",
    "                        ]\n",
    "                        ranked_pmlps_df = ranked_pmlps_df.sort_values(\n",
    "                            by=[holdout_metric, \"num_neurons\"],\n",
    "                            ascending=[False, True],\n",
    "                        )\n",
    "\n",
    "                    elif policy == \"0.01_smallest_mean_dist_holdout\":\n",
    "                        ranked_pmlps_df = ranked_pmlps_df.iloc[\n",
    "                            : int(ranked_pmlps_df.shape[0] * 0.01)\n",
    "                        ]\n",
    "                        ranked_pmlps_df = ranked_pmlps_df.sort_values(\n",
    "                            by=[holdout_metric, \"num_neurons\"],\n",
    "                            ascending=[False, True],\n",
    "                        )\n",
    "                    elif policy == \"topsis_pareto_oracle\":\n",
    "                        mcdm_tuples = [\n",
    "                            (\"num_neurons\", -1),\n",
    "                            (\"epoch\", 1),\n",
    "                            (test_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                        )\n",
    "                    elif (\n",
    "                        policy\n",
    "                        == \"topsis_train_validation_holdout_no_num_neurons_no_epochs\"\n",
    "                    ):\n",
    "                        mcdm_tuples = [\n",
    "                            (train_metric, 1),\n",
    "                            (validation_metric, 1),\n",
    "                            (holdout_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                        )\n",
    "                    elif policy == \"topsis_pareto_train_validation_holdout\":\n",
    "                        mcdm_tuples = [\n",
    "                            (\"num_neurons\", -1),\n",
    "                            (\"epoch\", 1),\n",
    "                            (train_metric, 1),\n",
    "                            (validation_metric, 1),\n",
    "                            (holdout_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                        )\n",
    "                    elif policy == \"topsis_pareto_train_validation_holdout_no_epochs\":\n",
    "                        mcdm_tuples = [\n",
    "                            (\"num_neurons\", -1),\n",
    "                            (train_metric, 1),\n",
    "                            (validation_metric, 1),\n",
    "                            (holdout_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                        )\n",
    "                    elif (\n",
    "                        policy\n",
    "                        == \"topsis_best_rank_architecture_pareto_train_validation_holdout_no_epochs\"\n",
    "                    ):\n",
    "                        mcdm_tuples = [\n",
    "                            (\"num_neurons\", -1),\n",
    "                            (train_metric, 1),\n",
    "                            (validation_metric, 1),\n",
    "                            (holdout_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=False,\n",
    "                            sort_by_rank=True,\n",
    "                        )\n",
    "                        best_architecture_id = (\n",
    "                            ranked_pmlps_df.groupby([\"rank\"])\n",
    "                            .median()\n",
    "                            .sort_values(by=[\"rank\"], ascending=[False])\n",
    "                            .iloc[0][\"architecture_id\"]\n",
    "                        )\n",
    "                        ranked_pmlps_df = ranked_pmlps_df[\n",
    "                            ranked_pmlps_df[\"architecture_id\"] == best_architecture_id\n",
    "                        ].sort_values(by=[\"rank\"], ascending=[False])\n",
    "                    elif (\n",
    "                        policy\n",
    "                        == \"topsis_pareto_oracle_holdout_no_epochs_no_num_neurons\"\n",
    "                    ):\n",
    "                        mcdm_tuples = [\n",
    "                            (holdout_metric, 1),\n",
    "                            (test_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                        )\n",
    "                    elif policy == \"topsis_pareto_oracle_holdout_train\":\n",
    "                        mcdm_tuples = [\n",
    "                            (\"num_neurons\", -1),\n",
    "                            (\"epoch\", 1),\n",
    "                            (train_metric, 1),\n",
    "                            (holdout_metric, 1),\n",
    "                            (test_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                        )\n",
    "                    elif policy == \"topsis_pareto_oracle_holdout_validation_train\":\n",
    "                        mcdm_tuples = [\n",
    "                            (\"num_neurons\", -1),\n",
    "                            (\"epoch\", 1),\n",
    "                            (train_metric, 1),\n",
    "                            (validation_metric, 1),\n",
    "                            (holdout_metric, 1),\n",
    "                            (test_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                        )\n",
    "                    elif (\n",
    "                        policy\n",
    "                        == \"topsis_pareto_oracle_holdout_validation_train_noepochs_nonum_neurons\"\n",
    "                    ):\n",
    "                        mcdm_tuples = [\n",
    "                            (train_metric, 1),\n",
    "                            (validation_metric, 1),\n",
    "                            (holdout_metric, 1),\n",
    "                            (test_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                        )\n",
    "                    elif (\n",
    "                        policy\n",
    "                        == \"topsis_pareto_oracle_holdout_train_noepochs_nonum_neurons\"\n",
    "                    ):\n",
    "                        mcdm_tuples = [\n",
    "                            (train_metric, 1),\n",
    "                            (holdout_metric, 1),\n",
    "                            (test_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                        )\n",
    "                    elif policy == \"topsis_pareto_holdout\":\n",
    "                        mcdm_tuples = [\n",
    "                            (\"num_neurons\", -1),\n",
    "                            (\"epoch\", 1),\n",
    "                            (holdout_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                        )\n",
    "                    elif policy == \"topsis_pareto_holdout_no_epochs_no_num_neurons\":\n",
    "                        mcdm_tuples = [\n",
    "                            (\"num_neurons\", -1),\n",
    "                            (holdout_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                        )\n",
    "                    elif policy == \"mairca_pareto_holdout\":\n",
    "                        mcdm_tuples = [\n",
    "                            (\"num_neurons\", -1),\n",
    "                            (\"epoch\", 1),\n",
    "                            (holdout_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                            mcdm_method_name=\"mairca\",\n",
    "                        )\n",
    "                    elif policy == \"mairca_pareto_holdout_reverse\":\n",
    "                        mcdm_tuples = [\n",
    "                            (\"num_neurons\", -1),\n",
    "                            (\"epoch\", 1),\n",
    "                            (holdout_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                            mcdm_method_name=\"mairca\",\n",
    "                        )\n",
    "                        ranked_pmlps_df = ranked_pmlps_df.sort_values(\n",
    "                            by=[\"rank\"], ascending=True\n",
    "                        )\n",
    "                    elif policy == \"moora_pareto_holdout\":\n",
    "                        mcdm_tuples = [\n",
    "                            (\"num_neurons\", -1),\n",
    "                            (\"epoch\", 1),\n",
    "                            (holdout_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                            mcdm_method_name=\"moora\",\n",
    "                        )\n",
    "                    elif policy == \"moora_pareto_holdout_inverse\":\n",
    "                        mcdm_tuples = [\n",
    "                            (\"num_neurons\", -1),\n",
    "                            (\"epoch\", 1),\n",
    "                            (holdout_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                            mcdm_method_name=\"moora\",\n",
    "                        )\n",
    "                        ranked_pmlps_df = ranked_pmlps_df.sort_values(\n",
    "                            by=[\"rank\"], ascending=True\n",
    "                        )\n",
    "                    elif policy == \"topsis_pareto_holdout_no_epochs\":\n",
    "                        mcdm_tuples = [\n",
    "                            (\"num_neurons\", -1),\n",
    "                            (holdout_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                        )\n",
    "                    elif policy == \"topsis_pareto_holdout_no_num_neurons\":\n",
    "                        mcdm_tuples = [\n",
    "                            (\"epoch\", 1),\n",
    "                            (holdout_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                        )\n",
    "                    elif (\n",
    "                        policy == \"topsis_pareto_holdout_weighted_neu-p3_epc-p1_hold-p6\"\n",
    "                    ):\n",
    "                        mcdm_tuples = [\n",
    "                            (\"num_neurons\", -1),\n",
    "                            (\"epoch\", 1),\n",
    "                            (holdout_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                            weights=np.array([0.3, 0.1, 0.6])\n",
    "                            # # weights = np.array([0.5, 0.4, 0.1])\n",
    "                        )\n",
    "                    elif (\n",
    "                        policy == \"topsis_pareto_holdout_weighted_neu-p1_epc-p1_hold-p8\"\n",
    "                    ):\n",
    "                        mcdm_tuples = [\n",
    "                            (\"num_neurons\", -1),\n",
    "                            (\"epoch\", 1),\n",
    "                            (holdout_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                            weights=np.array([0.1, 0.1, 0.8]),\n",
    "                        )\n",
    "                    elif policy == \"topsis_pareto_holdout_mean_diffs\":\n",
    "                        mcdm_tuples = [\n",
    "                            (\"num_neurons\", -1),\n",
    "                            (\"mean_diffs\", -1),\n",
    "                            (\"epoch\", 1),\n",
    "                            (holdout_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                        )\n",
    "                    elif policy == \"smallest_euclidian_holdout_test_utopic\":\n",
    "                        overall_accs = ranked_pmlps_df[\n",
    "                            [test_metric, holdout_metric]\n",
    "                        ].values\n",
    "                        utopic_accs = np.array([[1.0, 1.0]])\n",
    "                        ranked_pmlps_df.loc[:, \"euclidian_to_utopic\"] = np.sqrt(\n",
    "                            ((overall_accs - utopic_accs) ** 2).sum(1)\n",
    "                        )\n",
    "                        ranked_pmlps_df = ranked_pmlps_df.sort_values(\n",
    "                            by=[\"euclidian_to_utopic\", \"num_neurons\"],\n",
    "                            ascending=[True, True],\n",
    "                        )\n",
    "                        ranked_pmlps_df = ranked_pmlps_df.drop(\n",
    "                            columns=[\"euclidian_to_utopic\"]\n",
    "                        )\n",
    "                    elif policy == \"smallest_euclidian_holdout_test_utopic\":\n",
    "                        overall_accs = ranked_pmlps_df[\n",
    "                            [test_metric, holdout_metric]\n",
    "                        ].values\n",
    "                        utopic_accs = np.array([[1.0, 1.0]])\n",
    "                        ranked_pmlps_df.loc[:, \"euclidian_to_utopic\"] = np.sqrt(\n",
    "                            ((overall_accs - utopic_accs) ** 2).sum(1)\n",
    "                        )\n",
    "                        ranked_pmlps_df = ranked_pmlps_df.sort_values(\n",
    "                            by=[\"euclidian_to_utopic\", \"num_neurons\"],\n",
    "                            ascending=[True, True],\n",
    "                        )\n",
    "                        ranked_pmlps_df = ranked_pmlps_df.drop(\n",
    "                            columns=[\"euclidian_to_utopic\"]\n",
    "                        )\n",
    "\n",
    "                    elif policy == \"all_except_test\":\n",
    "                        mcdm_tuples = [\n",
    "                            (\"num_neurons\", -1),\n",
    "                            (\"epoch\", 1),\n",
    "                            (\"holdout_matthews_corrcoef\", 1),\n",
    "                            (\"holdout_overall_acc\", 1),\n",
    "                            (\"validation_matthews_corrcoef\", 1),\n",
    "                            (\"validation_overall_acc\", 1),\n",
    "                            (\"train_overall_acc\", 1),\n",
    "                            (\"train_matthews_corrcoef\", 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                        )\n",
    "                    elif policy == \"topsis_train_dhol\":\n",
    "                        mcdm_tuples = [\n",
    "                            (\"num_neurons\", -1),\n",
    "                            (\"epoch\", 1),\n",
    "                            (holdout_metric, 1),\n",
    "                            (validation_metric, 1),\n",
    "                            (train_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                        )\n",
    "                    elif policy == \"topsis_all_overall_acc_except_test\":\n",
    "                        mcdm_tuples = [\n",
    "                            (\"num_neurons\", -1),\n",
    "                            (\"epoch\", 1),\n",
    "                            (train_metric, 1),\n",
    "                            (holdout_metric, 1),\n",
    "                            (validation_metric, 1),\n",
    "                        ]\n",
    "                        ranked_pmlps_df = get_ranked_pmlps_df(\n",
    "                            pmlps_df,\n",
    "                            mcdm_tuples,\n",
    "                            only_pareto_solutions=True,\n",
    "                            sort_by_rank=True,\n",
    "                        )\n",
    "                    choice = ranked_pmlps_df.iloc[0].copy()\n",
    "                    choice[\"policy\"] = policy\n",
    "                    choices.append(choice)\n",
    "        df_policy = pd.DataFrame(choices)\n",
    "        df_policy.to_csv(policy_file_path)\n",
    "\n",
    "\n",
    "def plot_policies(df):\n",
    "    fig = px.scatter(\n",
    "        df,\n",
    "        x=holdout_metric,\n",
    "        y=test_metric,\n",
    "        color=\"dataset\",\n",
    "        # symbol=\"policy\",\n",
    "        facet_row=\"policy\",\n",
    "    )\n",
    "    fig.update_layout(height=1500)\n",
    "    fig.write_html(analysis_folder / \"choices_per_policy.html\")\n",
    "\n",
    "    fig = px.scatter_3d(\n",
    "        df,\n",
    "        x=holdout_metric,\n",
    "        y=test_metric,\n",
    "        z=\"num_neurons\",\n",
    "        color=\"policy\",\n",
    "    )\n",
    "    fig.write_html(analysis_folder / \"choices_per_policy_3d.html\")\n",
    "\n",
    "\n",
    "def plot_box_policies(df):\n",
    "    fig = px.box(\n",
    "        df,\n",
    "        x=\"policy\",\n",
    "        y=test_metric,\n",
    "        color=\"dataset\",\n",
    "        # symbol=\"policy\",\n",
    "        # facet_row=\"policy\",\n",
    "    )\n",
    "    # fig.update_layout(height=1500)\n",
    "    fig.write_html(analysis_folder / \"choices_per_policy_box.html\")\n",
    "\n",
    "\n",
    "def plot_times(df):\n",
    "    df = df.drop(\n",
    "        columns=[\n",
    "            \"min_neurons\",\n",
    "            \"max_neurons\",\n",
    "            \"epochs\",\n",
    "            \"repetitions\",\n",
    "            \"activation_functions\",\n",
    "            \"repetitions\",\n",
    "            \"parallel/sequential\",\n",
    "        ]\n",
    "    )\n",
    "    df = df.melt(id_vars=[\"num_samples\", \"num_features\", \"num_models\", \"device\"])\n",
    "    # fig = px.scatter_3d(\n",
    "    #     df,\n",
    "    #     x=\"num_features\",\n",
    "    #     y=\"num_samples\",\n",
    "    #     z=\"value\",\n",
    "    #     color=\"variable\",\n",
    "    #     symbol=\"device\",\n",
    "    # )\n",
    "    df_parallel = df[df[\"variable\"] == \"parallel\"]\n",
    "    df_sequential = df[df[\"variable\"] == \"sequential\"]\n",
    "    df = df.rename(columns={\"value\": \"seconds\", \"variable\": \"strategy\"})\n",
    "    for device in [\"cuda\", \"cpu\"]:\n",
    "        for strategy in [\"sequential\", \"parallel\"]:\n",
    "            # x = df_parallel[[\"seconds\"]]\n",
    "            # y = df_sequential[\"seconds\"]\n",
    "            df_tmp = df[(df[\"strategy\"] == strategy) & (df[\"device\"] == device)]\n",
    "            x = df_tmp[[\"num_samples\", \"num_features\"]]\n",
    "            y = df_tmp[[\"seconds\"]]\n",
    "\n",
    "            reg = LinearRegression().fit(x, y)\n",
    "            print(\n",
    "                f\"device {device}, strategy {strategy} - score: {reg.score(x, y)}, coef: {reg.coef_}, incercept: {reg.intercept_}\"\n",
    "            )\n",
    "\n",
    "    # fig = px.scatter(df, x=\"num_samples\", y=\"value\", facet_row=\"variable\", facet_col=\"num_features\", trendline=\"ols\").show()\n",
    "    fig = px.scatter(\n",
    "        df,\n",
    "        x=\"num_samples\",\n",
    "        y=\"seconds\",\n",
    "        facet_row=\"strategy\",\n",
    "        facet_col=\"num_features\",\n",
    "        trendline=\"ols\",\n",
    "        category_orders={\"num_features\": [5, 10, 50, 100]},\n",
    "    )  # ,\n",
    "    fig.update_layout(yaxis_title=\"Seconds\")\n",
    "    # category_orders={\"day\": [\"Thur\", \"Fri\", \"Sat\", \"Sun\"], \"time\": [\"Lunch\", \"Dinner\"]})\n",
    "    # fig.show()\n",
    "    #     fig = make_subplots(rows=2, cols=1)\n",
    "    #     fig.add_trace(\n",
    "    #         go.Scatter(x=df_parallel[\"num_samples\"], y=df_parallel[\"num_features\"], size=\"value\"), row=1, col=1\n",
    "    #     )\n",
    "    #     fig.add_trace(\n",
    "    #         go.Scatter(x=df_sequential[\"num_samples\"], y=df_sequential[\"num_features\"], size=\"value\"), row=2, col=1\n",
    "    #     )\n",
    "    #     fig.update_layout(height=600, width=800, title_text=\"Epoch time average to train 10,000 models.\")\n",
    "    fig.show()\n",
    "\n",
    "    fig.write_html(analysis_folder / \"times.html\")\n",
    "\n",
    "\n",
    "def distance_to_optimals(original_df, df_policies):\n",
    "    best_test_df = (\n",
    "        original_df.sort_values(by=[test_metric], ascending=False)\n",
    "        .groupby([\"experiment\", \"dataset\", \"run\"])\n",
    "        .head(1)\n",
    "        .reset_index()\n",
    "    )\n",
    "    best_gap = (\n",
    "        original_df.sort_values(by=[test_metric], ascending=False)\n",
    "        .groupby([\"experiment\", \"dataset\", \"run\"])\n",
    "        .head(100)\n",
    "        .reset_index()\n",
    "    )\n",
    "    best_gap = (\n",
    "        best_gap.sort_values(by=[\"mean_diffs\"], ascending=True)\n",
    "        .groupby([\"experiment\", \"dataset\", \"run\"])\n",
    "        .head(1)\n",
    "    )\n",
    "    df_merge = df_policies.merge(\n",
    "        best_test_df[[\"experiment\", \"dataset\", \"run\", test_metric]],\n",
    "        on=[\"experiment\", \"dataset\", \"run\"],\n",
    "        suffixes=(\"\", \"_best_test\"),\n",
    "    )\n",
    "    df_merge = df_merge.merge(\n",
    "        best_gap[[\"experiment\", \"dataset\", \"run\", \"mean_diffs\"]],\n",
    "        on=[\"experiment\", \"dataset\", \"run\"],\n",
    "        suffixes=(\"\", \"_best_gap\"),\n",
    "    )\n",
    "\n",
    "    df_merge[\"distance_to_test_oracle\"] = (\n",
    "        df_merge[f\"test_{metric}_best_test\"] - df_merge[test_metric]\n",
    "    ).abs()\n",
    "    df_merge[\"distance_to_best_mean_diffs\"] = (\n",
    "        df_merge[\"mean_diffs_best_gap\"] - df_merge[\"mean_diffs\"]\n",
    "    ).abs()\n",
    "\n",
    "    fig = px.scatter(\n",
    "        df_merge.groupby([\"policy\"]).mean().reset_index(),\n",
    "        x=\"distance_to_best_mean_diffs\",\n",
    "        y=\"distance_to_test_oracle\",\n",
    "        color=\"policy\",\n",
    "        size=\"num_neurons\"\n",
    "        # symbol=\"policy\",\n",
    "        # facet_row=\"policy\",\n",
    "    )\n",
    "    fig.write_html(analysis_folder / \"distance_to_bests.html\")\n",
    "\n",
    "    fig = px.scatter(\n",
    "        df_merge.groupby([\"policy\"]).mean().reset_index(),\n",
    "        x=holdout_metric,\n",
    "        y=test_metric,\n",
    "        color=\"policy\",\n",
    "        size=\"num_neurons\"\n",
    "        # symbol=\"policy\",\n",
    "        # facet_row=\"policy\",\n",
    "    )\n",
    "    fig.write_html(analysis_folder / \"mean_holdout_test__policy.html\")\n",
    "\n",
    "    fig = px.scatter_3d(\n",
    "        df_merge.groupby([\"policy\"]).mean().reset_index(),\n",
    "        x=holdout_metric,\n",
    "        y=test_metric,\n",
    "        z=train_metric,\n",
    "        color=\"policy\",\n",
    "        size=\"num_neurons\"\n",
    "        # symbol=\"policy\",\n",
    "        # facet_row=\"policy\",\n",
    "    )\n",
    "    fig.write_html(analysis_folder / \"3d_mean_train_holdout_test__policy.html\")\n",
    "\n",
    "    fig = px.box(\n",
    "        df_merge,  # .groupby([\"policy\"]),#.mean().reset_index(),\n",
    "        y=\"distance_to_test_oracle\",\n",
    "        # y=\"distance_to_best_mean_diffs\",\n",
    "        color=\"policy\",\n",
    "        # size=\"num_neurons\"\n",
    "        # symbol=\"policy\",\n",
    "        # facet_row=\"policy\",\n",
    "    )\n",
    "    # order = df_policies.groupby([\"policy\"]).median().sort_values(by=[test_metric]).reset_index()[\"policy\"].values.tolist()\n",
    "    fig.write_html(analysis_folder / \"policy_boxplots.html\")\n",
    "\n",
    "    # fig = make_subplots(1, 1)\n",
    "    # fig.add_trace(\n",
    "    #     go.Scatter(x=optimal_gap_model, y=df_parallel[\"num_features\"], size=\"value\"), row=1, col=1\n",
    "    # )\n",
    "    # fig = px.scatter(df_gap, x=\"num_samples\", y=\"seconds\", facet_row=\"strategy\", facet_col=\"num_features\", trendline=\"ols\", category_orders={\"num_features\": [5, 10,50,100]})#,\n",
    "\n",
    "\n",
    "def sbss_vs_nosbss_plots(df_policies):\n",
    "    fig = px.box(\n",
    "        df_policies,  # .groupby([\"policy\"]),#.mean().reset_index(),\n",
    "        y=test_metric,\n",
    "        x=\"policy\",\n",
    "        color=\"experiment\",\n",
    "        # size=\"num_neurons\"\n",
    "        # symbol=\"policy\",\n",
    "        # facet_row=\"policy\",\n",
    "    )\n",
    "    # order = df_policies.groupby([\"policy\"]).median().sort_values(by=[test_metric]).reset_index()[\"policy\"].values.tolist()\n",
    "    fig.write_html(analysis_folder / \"sbss_vs_nosbss.html\")\n",
    "\n",
    "    fig = px.scatter(\n",
    "        df_policies.groupby([\"experiment\", \"policy\"]).mean().reset_index(),\n",
    "        x=holdout_metric,\n",
    "        y=test_metric,\n",
    "        color=\"policy\",\n",
    "        size=\"num_neurons\",\n",
    "        symbol=\"experiment\",\n",
    "        # facet_row=\"policy\",\n",
    "    )\n",
    "    fig.write_html(analysis_folder / \"sbss_vs_nosbss_mean_holdout_test__policy.html\")\n",
    "\n",
    "    d = df_policies.groupby([\"experiment\", \"policy\"]).mean().reset_index()\n",
    "    d2 = d.pivot_table(\n",
    "        [\n",
    "            train_metric,\n",
    "            validation_metric,\n",
    "            holdout_metric,\n",
    "            test_metric,\n",
    "            \"num_neurons\",\n",
    "            \"mean_diffs\",\n",
    "        ],\n",
    "        [\"policy\"],\n",
    "        \"experiment\",\n",
    "    )\n",
    "    d2.to_csv(analysis_folder / \"sbss_vs_nosbss.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j5/xxfd1lnd7tq44hb0gjt2835c0000gn/T/ipykernel_44841/3705726773.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_policies.groupby([\"policy\"])[train_metric, validation_metric, holdout_metric, test_metric, \"num_neurons\"].mean().reset_index().sort_values(by=[test_metric, holdout_metric, validation_metric, train_metric, \"num_neurons\"], ascending=[False, False, False, False, True])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy</th>\n",
       "      <th>train_overall_acc</th>\n",
       "      <th>validation_overall_acc</th>\n",
       "      <th>holdout_overall_acc</th>\n",
       "      <th>test_overall_acc</th>\n",
       "      <th>num_neurons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>oracle</td>\n",
       "      <td>0.874190</td>\n",
       "      <td>0.870733</td>\n",
       "      <td>0.876774</td>\n",
       "      <td>0.906056</td>\n",
       "      <td>42.797619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>smallest_euclidian_holdout_test_utopic</td>\n",
       "      <td>0.910688</td>\n",
       "      <td>0.889853</td>\n",
       "      <td>0.907831</td>\n",
       "      <td>0.897913</td>\n",
       "      <td>73.384921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>topsis_pareto_oracle_holdout_no_epochs_no_num_...</td>\n",
       "      <td>0.912190</td>\n",
       "      <td>0.890469</td>\n",
       "      <td>0.908967</td>\n",
       "      <td>0.896501</td>\n",
       "      <td>75.503968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>topsis_pareto_oracle_holdout_train_noepochs_no...</td>\n",
       "      <td>0.915068</td>\n",
       "      <td>0.886401</td>\n",
       "      <td>0.909790</td>\n",
       "      <td>0.895223</td>\n",
       "      <td>76.301587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>topsis_pareto_oracle_holdout_train</td>\n",
       "      <td>0.875655</td>\n",
       "      <td>0.855991</td>\n",
       "      <td>0.872147</td>\n",
       "      <td>0.860612</td>\n",
       "      <td>9.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>topsis_pareto_oracle</td>\n",
       "      <td>0.843981</td>\n",
       "      <td>0.833552</td>\n",
       "      <td>0.843171</td>\n",
       "      <td>0.857900</td>\n",
       "      <td>6.099206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>holdout</td>\n",
       "      <td>0.920795</td>\n",
       "      <td>0.899391</td>\n",
       "      <td>0.917642</td>\n",
       "      <td>0.855444</td>\n",
       "      <td>76.408730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>topsis_pareto_holdout_no_num_neurons</td>\n",
       "      <td>0.918568</td>\n",
       "      <td>0.892208</td>\n",
       "      <td>0.913746</td>\n",
       "      <td>0.852204</td>\n",
       "      <td>75.202381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>best_holdout_in_best_architecture_10fold</td>\n",
       "      <td>0.915230</td>\n",
       "      <td>0.893808</td>\n",
       "      <td>0.912057</td>\n",
       "      <td>0.851204</td>\n",
       "      <td>87.134921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>moora_pareto_holdout_inverse</td>\n",
       "      <td>0.905356</td>\n",
       "      <td>0.882754</td>\n",
       "      <td>0.901979</td>\n",
       "      <td>0.842682</td>\n",
       "      <td>75.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>validation</td>\n",
       "      <td>0.878467</td>\n",
       "      <td>0.918583</td>\n",
       "      <td>0.889682</td>\n",
       "      <td>0.842465</td>\n",
       "      <td>47.019841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>topsis_pareto_holdout_weighted_neu-p1_epc-p1_h...</td>\n",
       "      <td>0.903410</td>\n",
       "      <td>0.884871</td>\n",
       "      <td>0.900622</td>\n",
       "      <td>0.840644</td>\n",
       "      <td>26.988095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01_smallest_mean_dist_holdout</td>\n",
       "      <td>0.883980</td>\n",
       "      <td>0.883969</td>\n",
       "      <td>0.884037</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>33.726190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all_except_test</td>\n",
       "      <td>0.883833</td>\n",
       "      <td>0.887585</td>\n",
       "      <td>0.885526</td>\n",
       "      <td>0.835664</td>\n",
       "      <td>15.865079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>topsis_pareto_holdout_weighted_neu-p3_epc-p1_h...</td>\n",
       "      <td>0.883731</td>\n",
       "      <td>0.871786</td>\n",
       "      <td>0.882055</td>\n",
       "      <td>0.829653</td>\n",
       "      <td>11.261905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>topsis_all_overall_acc_except_test</td>\n",
       "      <td>0.875286</td>\n",
       "      <td>0.877879</td>\n",
       "      <td>0.876573</td>\n",
       "      <td>0.829591</td>\n",
       "      <td>10.773810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>topsis_pareto_train_validation_holdout</td>\n",
       "      <td>0.875286</td>\n",
       "      <td>0.877879</td>\n",
       "      <td>0.876573</td>\n",
       "      <td>0.829591</td>\n",
       "      <td>10.773810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>topsis_holdout_in_best_median_architecture_10f...</td>\n",
       "      <td>0.864705</td>\n",
       "      <td>0.855051</td>\n",
       "      <td>0.864216</td>\n",
       "      <td>0.821871</td>\n",
       "      <td>6.718254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>topsis_pareto_holdout</td>\n",
       "      <td>0.864663</td>\n",
       "      <td>0.856165</td>\n",
       "      <td>0.864427</td>\n",
       "      <td>0.821633</td>\n",
       "      <td>6.662698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>topsis_pareto_holdout_no_epochs</td>\n",
       "      <td>0.868625</td>\n",
       "      <td>0.862721</td>\n",
       "      <td>0.868786</td>\n",
       "      <td>0.821454</td>\n",
       "      <td>6.690476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>topsis_pareto_holdout_mean_diffs</td>\n",
       "      <td>0.859366</td>\n",
       "      <td>0.858153</td>\n",
       "      <td>0.859829</td>\n",
       "      <td>0.818826</td>\n",
       "      <td>7.023810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mairca_pareto_holdout_reverse</td>\n",
       "      <td>0.858966</td>\n",
       "      <td>0.849320</td>\n",
       "      <td>0.859215</td>\n",
       "      <td>0.818090</td>\n",
       "      <td>5.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>moora_pareto_holdout</td>\n",
       "      <td>0.839694</td>\n",
       "      <td>0.832990</td>\n",
       "      <td>0.840874</td>\n",
       "      <td>0.807798</td>\n",
       "      <td>3.496032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mairca_pareto_holdout</td>\n",
       "      <td>0.836119</td>\n",
       "      <td>0.820855</td>\n",
       "      <td>0.834591</td>\n",
       "      <td>0.786961</td>\n",
       "      <td>68.539683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               policy  train_overall_acc  \\\n",
       "8                                              oracle           0.874190   \n",
       "9              smallest_euclidian_holdout_test_utopic           0.910688   \n",
       "19  topsis_pareto_oracle_holdout_no_epochs_no_num_...           0.912190   \n",
       "21  topsis_pareto_oracle_holdout_train_noepochs_no...           0.915068   \n",
       "20                 topsis_pareto_oracle_holdout_train           0.875655   \n",
       "18                               topsis_pareto_oracle           0.843981   \n",
       "3                                             holdout           0.920795   \n",
       "15               topsis_pareto_holdout_no_num_neurons           0.918568   \n",
       "2            best_holdout_in_best_architecture_10fold           0.915230   \n",
       "7                        moora_pareto_holdout_inverse           0.905356   \n",
       "23                                         validation           0.878467   \n",
       "16  topsis_pareto_holdout_weighted_neu-p1_epc-p1_h...           0.903410   \n",
       "0                     0.01_smallest_mean_dist_holdout           0.883980   \n",
       "1                                     all_except_test           0.883833   \n",
       "17  topsis_pareto_holdout_weighted_neu-p3_epc-p1_h...           0.883731   \n",
       "10                 topsis_all_overall_acc_except_test           0.875286   \n",
       "22             topsis_pareto_train_validation_holdout           0.875286   \n",
       "11  topsis_holdout_in_best_median_architecture_10f...           0.864705   \n",
       "12                              topsis_pareto_holdout           0.864663   \n",
       "14                    topsis_pareto_holdout_no_epochs           0.868625   \n",
       "13                   topsis_pareto_holdout_mean_diffs           0.859366   \n",
       "5                       mairca_pareto_holdout_reverse           0.858966   \n",
       "6                                moora_pareto_holdout           0.839694   \n",
       "4                               mairca_pareto_holdout           0.836119   \n",
       "\n",
       "    validation_overall_acc  holdout_overall_acc  test_overall_acc  num_neurons  \n",
       "8                 0.870733             0.876774          0.906056    42.797619  \n",
       "9                 0.889853             0.907831          0.897913    73.384921  \n",
       "19                0.890469             0.908967          0.896501    75.503968  \n",
       "21                0.886401             0.909790          0.895223    76.301587  \n",
       "20                0.855991             0.872147          0.860612     9.571429  \n",
       "18                0.833552             0.843171          0.857900     6.099206  \n",
       "3                 0.899391             0.917642          0.855444    76.408730  \n",
       "15                0.892208             0.913746          0.852204    75.202381  \n",
       "2                 0.893808             0.912057          0.851204    87.134921  \n",
       "7                 0.882754             0.901979          0.842682    75.523810  \n",
       "23                0.918583             0.889682          0.842465    47.019841  \n",
       "16                0.884871             0.900622          0.840644    26.988095  \n",
       "0                 0.883969             0.884037          0.839500    33.726190  \n",
       "1                 0.887585             0.885526          0.835664    15.865079  \n",
       "17                0.871786             0.882055          0.829653    11.261905  \n",
       "10                0.877879             0.876573          0.829591    10.773810  \n",
       "22                0.877879             0.876573          0.829591    10.773810  \n",
       "11                0.855051             0.864216          0.821871     6.718254  \n",
       "12                0.856165             0.864427          0.821633     6.662698  \n",
       "14                0.862721             0.868786          0.821454     6.690476  \n",
       "13                0.858153             0.859829          0.818826     7.023810  \n",
       "5                 0.849320             0.859215          0.818090     5.555556  \n",
       "6                 0.832990             0.840874          0.807798     3.496032  \n",
       "4                 0.820855             0.834591          0.786961    68.539683  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_policies_comparison(df_policies):\n",
    "\tdf_policies.groupby([\"experiment\", \"run\", \"dataset\"])[train_metric, validation_metric, holdout_metric, test_metric].mean()\n",
    "\n",
    "# plot_policies_comparison(df_policies)\n",
    "df_policies.groupby([\"policy\"])[train_metric, validation_metric, holdout_metric, test_metric, \"num_neurons\"].mean().reset_index().sort_values(by=[test_metric, holdout_metric, validation_metric, train_metric, \"num_neurons\"], ascending=[False, False, False, False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_specific_dataset=df.copy()#[(df[\"dataset\"] == \"diabetes\")]\n",
    "\n",
    "mcdm_tuples = [\n",
    "\t(holdout_metric, 1),\n",
    "\t(test_metric, 1),\n",
    "]\n",
    "df_pareto = df.copy().groupby([\"dataset\"]).apply(lambda x:get_ranked_pmlps_df(pmlps_df=x, mcdm_tuples=mcdm_tuples, mcdm_method_name=None))\n",
    "\n",
    "# df_pareto = get_ranked_pmlps_df(df.copy(), mcdm_tuples, mcdm_method_name=None, only_pareto_solutions=True, sort_by_rank=False)\n",
    "\n",
    "df_pareto = df_pareto.sort_values([holdout_metric]).sort_values([test_metric])\n",
    "# fig = px.scatter(df, x=holdout_metric, y=test_metric, color=\"dataset\", symbol=\"dataset\", color_discrete_sequence=px.colors.qualitative.Alphabet)#, title=\"Pareto distribution for each dataset\")\n",
    "fig = px.scatter(df, x=holdout_metric, y=test_metric, color_discrete_sequence=px.colors.qualitative.Alphabet, facet_col=\"dataset\", width=600, height=300)#, title=\"Pareto distribution for each dataset\")\n",
    "fig.update_layout({\"xaxis_title\": f\"Holdout Acc\", \"yaxis_title\": f\"Test Acc\"})\n",
    "# fig.update_layout(showlegend=False)\n",
    "plotly.io.write_image(fig, analysis_folder / 'all_holdout_test_datasets.pdf', format='pdf')\n",
    "\n",
    "# fig = px.line(df_pareto, x=holdout_metric, y=test_metric, color=\"dataset\", symbol=\"dataset\", color_discrete_sequence=px.colors.qualitative.Alphabet)#, title=\"Pareto distribution for each dataset\")\n",
    "# fig.update_layout({\"xaxis_title\": f\"Holdout Acc\", \"yaxis_title\": f\"Test Acc\"})\n",
    "# plotly.io.write_image(fig, analysis_folder / 'df_pareto_distribution_for_each_dataset.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'Unnamed: 0', 'model_id', 'selected', 'fold', 'repetition',\n",
      "       'num_neurons', 'weight_regularization', 'monitored_metric', 'loss',\n",
      "       'epoch', 'activation_name', 'architecture_id', 'train_overall_acc',\n",
      "       'train_matthews_corrcoef', 'validation_overall_acc',\n",
      "       'validation_matthews_corrcoef', 'holdout_overall_acc',\n",
      "       'holdout_matthews_corrcoef', 'test_overall_acc',\n",
      "       'test_matthews_corrcoef', 'dominant_solution', 'mean_diffs', 'dataset',\n",
      "       'run', 'experiment', 'validation_loss', 'holdout_loss'],\n",
      "      dtype='object')\n",
      "df.shape: (1512000, 28)\n",
      "datase: ['ionosphere' 'diabetes' 'Australian' 'car(3)' 'credit-g'\n",
      " 'climate-model-simulation-crashes(4)' 'ilpd' 'balance-scale'\n",
      " 'libras_move' 'blood-transfusion-service-center' 'lsvt' 'wdbc' 'satimage'\n",
      " 'vowel(2)' 'musk']\n",
      "df_policies.shape: (6480, 32)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_policies_comparison' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/fcf/projects/parallel_mlps/analysis/selection_analysis.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fcf/projects/parallel_mlps/analysis/selection_analysis.ipynb#ch0000002?line=7'>8</a>\u001b[0m df_policies \u001b[39m=\u001b[39m load_df_policies()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fcf/projects/parallel_mlps/analysis/selection_analysis.ipynb#ch0000002?line=9'>10</a>\u001b[0m \u001b[39m# print(df.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fcf/projects/parallel_mlps/analysis/selection_analysis.ipynb#ch0000002?line=10'>11</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fcf/projects/parallel_mlps/analysis/selection_analysis.ipynb#ch0000002?line=11'>12</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fcf/projects/parallel_mlps/analysis/selection_analysis.ipynb#ch0000002?line=24'>25</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fcf/projects/parallel_mlps/analysis/selection_analysis.ipynb#ch0000002?line=25'>26</a>\u001b[0m \u001b[39m# plot_box_policies(df_policies)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/fcf/projects/parallel_mlps/analysis/selection_analysis.ipynb#ch0000002?line=27'>28</a>\u001b[0m plot_policies_comparison(df_policies)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_policies_comparison' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(df.shape)\n",
    "\n",
    "\n",
    "# plot_holdout_test(df)\n",
    "# # debug_ilpd(df)\n",
    "\n",
    "# num_models(df)\n",
    "\n",
    "# df_policies = apply_policies(df)\n",
    "\n",
    "# sbss_vs_nosbss_plots(df_policies)\n",
    "\n",
    "\n",
    "# distance_to_optimals(df, df_policies)\n",
    "# plot_policies(df_policies)\n",
    "\n",
    "# plot_box_policies(df_policies)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d455b01b295f5d3dab18bd6721a175479d3842dad2f173c2a4b8ea468a814f49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('doutorado')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
